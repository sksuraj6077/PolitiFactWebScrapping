# -*- coding: utf-8 -*-
"""FinalP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1muxMNmaJzv1f82Nh0WFEcIXKgbIfnV5A
"""

from bs4 import BeautifulSoup
import pandas as pd
import requests
import urllib.request
import time

authors = []
statements = []
targets = []
text_1 = []
url_1 = []
d = {}

def scrape_website(page_number, category):
    page_num = str(page_number)
    #https://www.politifact.com/factchecks/list/?page=10&category=california
    URL = 'https://www.politifact.com/factchecks/list/?page={}&category={}'.format(page_num, category)
    
    webpage = requests.get(URL) 
    #time.sleep(3)
    soup = BeautifulSoup(webpage.text, "html.parser") #Parse the text from the website
    
    statement_footer =  soup.find_all('footer',attrs={'class':'m-statement__footer'}) 
    statement_quote = soup.find_all('div', attrs={'class':'m-statement__quote'})
    statement_meta = soup.find_all('div', attrs={'class':'m-statement__meta'})
    #statement_text = soup.find_all('div',attrs={'short-on-time'})
    target = soup.find_all('div', attrs={'class':'m-statement__meter'}) 
    for i in statement_footer:
        link1 = i.text.strip()
        name_and_date = link1.split()
        first_name = name_and_date[1]
        last_name = name_and_date[2]
        full_name = first_name+' '+last_name
        authors.append(full_name)


    # for i in statement_quote:
    #     link2 = i.find_all('a')
    #     statements.append(link2[0].text.strip())
    # #for i in statement_text:
    #     link0 = i.find_all('a')
    #     #print(i)
    #     text_1.append(link0[0].text.strip())

    for i in statement_quote:
      for link in i.find_all('a',href=True):
        statements.append(i.text)
        url_1.append("https://www.politifact.com"+link['href'])
    for link1 in url_1:
      webpage1 = requests.get(link1)
      soup1 = BeautifulSoup(webpage1.text, "html.parser") 
      statement_text = soup1.find_all('div',attrs={'short-on-time'})
      text_1.append(statement_text[0].text)
    for x in range(len(statements)):
      d[statements[x]]=text_1[x]



    for i in target:
        fact = i.find('div', attrs={'class':'c-image'}).find('img').get('alt')
        targets.append(fact)

#florida
#california
n=2
for i in range(1, n):
    scrape_website(i, category='illinois')

data = pd.DataFrame(columns = ['Title','Author','Text','Target','Label'])
data['Author'] = authors
data['Title'] = statements
#data['Label'] = 
data['Text'] = d.values()
data['Target'] = targets
print(text_1)
data
#data.iloc[:5].to_csv('politifact-joe-biden-sample.csv', index=False, sep=',')

def getBinaryNumTarget(text):
    if text == 'true':
        return 1
    elif text == 'mostly-true':
        return 1
    else:
        return 0

data['Label']=data['Target'].apply(getBinaryNumTarget)

data